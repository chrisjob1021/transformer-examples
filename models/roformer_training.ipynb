{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a6763ed989490bab32120857cdaa0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from utils import TrainingConfig, Config\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")   # or your custom one\n",
    "\n",
    "training_config = TrainingConfig()\n",
    "config = Config(vocab_size=tokenizer.vocab_size,\n",
    "    d_model=768, num_heads=12, ffn_dim=3072,\n",
    "    num_layers=12, )\n",
    "\n",
    "# 1. Load the raw text\n",
    "ds = load_dataset(\"openwebtext\", split=\"train\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Port-au-Prince, Haiti (CNN) -- Earthquake victims, writhing in pain and grasping at life, watched doctors and nurses walk away from a field hospital Friday night after a Belgian medical team evacuated the area, saying it was concerned about security.\\n\\nThe decision left CNN Chief Medical Correspondent Sanjay Gupta as the only doctor at the hospital to get the patients through the night.\\n\\nCNN initially reported, based on conversations with some of the doctors, that the United Nations ordered the Belgian First Aid and Support Team to evacuate. However, Belgian Chief Coordinator Geert Gijs, a doctor who was at the hospital with 60 Belgian medical personnel, said it was his decision to pull the team out for the night. Gijs said he requested U.N. security personnel to staff the hospital overnight, but was told that peacekeepers would only be able to evacuate the team.\\n\\nHe said it was a \"tough decision\" but that he accepted the U.N. offer to evacuate after a Canadian medical team, also at the hospital with Canadian security officers, left the site Friday afternoon. The Belgian team returned Saturday morning.\\n\\nGijs said the United Nations has agreed to provide security for Saturday night. The team has requested the Belgian government to send its own troops for the field hospital, which Gijs expects to arrive late Sunday.\\n\\nResponding to the CNN report that Gupta was the only doctor left at the Port-au-Prince field hospital, U.N. spokesman Martin Nesirky said Saturday that the world body\\'s mission in Haiti did not order any medical team to leave. If the team left, it was at the request of their own organization, he said.\\n\\nEdmond Mulet, the U.N. assistant secretary general for peacekeeping operations, told reporters later that local security officers deemed the makeshift hospital unsafe.\\n\\n\"It seems that we\\'ve heard some reports in the international media that the United Nations asked or forced some medical teams to not work any more in some clinic -- that is not true, that is completely untrue,\" Mulet said Saturday.\\n\\nCNN video from the scene Friday night shows the Belgian team packing up its supplies and leaving with an escort of blue-helmeted U.N. peacekeepers in marked trucks.\\n\\nView or add to CNN\\'s database of missing persons in Haiti\\n\\nGupta -- assisted by other CNN staffers, security personnel and at least one Haitian nurse who refused to leave -- assessed the needs of the 25 patients, but there was little they could do without supplies.\\n\\nMore people, some in critical condition, were trickling in late Friday.\\n\\n\"I\\'ve never been in a situation like this. This is quite ridiculous,\" Gupta said.\\n\\nWith a dearth of medical facilities in Haiti\\'s capital, ambulances had nowhere else to take patients, some of whom had suffered severe trauma -- amputations and head injuries -- under the rubble. Others had suffered a great deal of blood loss, but there were no blood supplies left at the clinic.\\n\\nGupta feared that some would not survive the night.\\n\\nHe and the others stayed with the injured all night, after the medical team had left and after the generators gave out and the tents turned pitch black.\\n\\nGupta monitored patients\\' vital signs, administered painkillers and continued intravenous drips. He stabilized three new patients in critical condition.\\n\\nAt 3:45 a.m., he posted a message on Twitter: \"pulling all nighter at haiti field hosp. lots of work, but all patients stable. turned my crew into a crack med team tonight.\"\\n\\nAre you in Haiti and safe? Share your photos\\n\\nHe said the Belgian doctors did not want to leave their patients behind but were ordered out by the United Nations, which sent buses to transport them.\\n\\n\"There is concern about riots not far from here -- and this is part of the problem,\" Gupta said.\\n\\nThere have been scattered reports of violence throughout the capital.\\n\\n\"What is striking to me as a physician is that patients who just had surgery, patients who are critically ill, are essentially being left here, nobody to care for them,\" Gupta said.\\n\\nSandra Pierre, a Haitian who has been helping at the makeshift hospital, said the medical staff took most of the supplies with them.\\n\\n\"All the doctors, all the nurses are gone,\" she said. \"They are expected to be back tomorrow. They had no plan on leaving tonight. It was an order that came suddenly.\"\\n\\nShe told Gupta, \"It\\'s just you.\"\\n\\nA 7.0 magnitude earthquake flattened Haiti\\'s capital city Tuesday afternoon, affecting as many as 3 million people as it fanned out across the island nation. Tens of thousands of people are feared dead.\\n\\nHaiti, the poorest nation in the Western hemisphere, lacked adequate medical resources even before the disaster and has been struggling this week to tend to huge numbers of injured. The clinic, set up under several tents, was a godsend to the few who were lucky to have been brought there.\\n\\nRetired Army Lt. Gen. Russel Honore, who led relief efforts for Hurricane Katrina in 2005, said the evacuation of the clinic\\'s medical staff was unforgivable.\\n\\n\"Search and rescue must trump security,\" Honoré said. \"I\\'ve never seen anything like this before in my life. They need to man up and get back in there.\"\\n\\nHonoré drew parallels between the tragedy in New Orleans, Louisiana, and in Port-au-Prince. But even in the chaos of Katrina, he said, he had never seen medical staff walk away.\\n\\n\"I find this astonishing these doctors left,\" he said. \"People are scared of the poor.\"\\n\\nCNN\\'s Justine Redman, Danielle Dellorto and John Bonifield contributed to this report.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.select(range(1000))\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        # truncation=False,\n",
    "        # max_length=training_config.max_len,\n",
    "        # padding=False,\n",
    "        # return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "tokenized = ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "tokenized = tokenized.remove_columns([\"attention_mask\"])\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'labels'],\n",
       "    num_rows: 1099\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group(batch):\n",
    "    # Flattens the input_ids and attention_mask into single lists\n",
    "    flat_ids = sum(batch[\"input_ids\"], [])\n",
    "\n",
    "    num_of_complete_blocks = len(flat_ids) // config.max_seq_len\n",
    "    total = num_of_complete_blocks * config.max_seq_len\n",
    "    flat_ids = flat_ids[:total+1]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": [flat_ids[i:i+config.max_seq_len] for i in range(0, total, config.max_seq_len)],\n",
    "        \"labels\": [flat_ids[i+1:i+config.max_seq_len+1] for i in range(0, total, config.max_seq_len)]\n",
    "    }\n",
    "\n",
    "\n",
    "lm_ds = tokenized.map(group, batched=True, batch_size=10000)\n",
    "lm_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from roformer import RoFormerEncoder, RoFormerForCausalLM\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "model_base = RoFormerEncoder(config)\n",
    "model = RoFormerForCausalLM(model_base, config)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"roformer-base\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=10,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=5,\n",
    "    save_strategy=\"steps\",\n",
    "    save_safetensors=False,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=lm_ds,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  262,  1398,   286,  8233, 11663], device='cuda:0')\n",
      "Sample labels: tensor([  262,  1398,   286,  8233, 11663], device='cuda:0')\n",
      "Sample logits max values: 524.0044555664062\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([4148,  803,  262, 4048, 1767], device='cuda:0')\n",
      "Sample labels: tensor([4148,  803,  262, 4048, 1767], device='cuda:0')\n",
      "Sample logits max values: 485.8727722167969\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([3712, 8367,   62, 4906,  318], device='cuda:0')\n",
      "Sample labels: tensor([3712, 8367,   62, 4906,  318], device='cuda:0')\n",
      "Sample logits max values: 498.9340515136719\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 326,  691, 1450,  422,  607], device='cuda:0')\n",
      "Sample labels: tensor([ 326,  691, 1450,  422,  607], device='cuda:0')\n",
      "Sample logits max values: 517.0106201171875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 625,  867, 2450, 3006,  290], device='cuda:0')\n",
      "Sample labels: tensor([ 625,  867, 2450, 3006,  290], device='cuda:0')\n",
      "Sample logits max values: 482.2361145019531\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([16476,   326,   340,  6989,   422], device='cuda:0')\n",
      "Sample labels: tensor([16476,   326,   340,  6989,   422], device='cuda:0')\n",
      "Sample logits max values: 481.509033203125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([8959,   44, 4304,   48,   13], device='cuda:0')\n",
      "Sample labels: tensor([8959,   44, 4304,   48,   13], device='cuda:0')\n",
      "Sample logits max values: 533.1610107421875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([1662,  354, 8286, 6504,  290], device='cuda:0')\n",
      "Sample labels: tensor([1662,  354, 8286, 6504,  290], device='cuda:0')\n",
      "Sample logits max values: 492.15142822265625\n",
      "loss: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 16/102 00:27 < 02:48, 0.51 it/s, Epoch 0.44/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  534, 43376, 10547,   290, 42591], device='cuda:0')\n",
      "Sample labels: tensor([  534, 43376, 10547,   290, 42591], device='cuda:0')\n",
      "Sample logits max values: 494.0541076660156\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([6492,   13,  198,  198,  818], device='cuda:0')\n",
      "Sample labels: tensor([6492,   13,  198,  198,  818], device='cuda:0')\n",
      "Sample logits max values: 495.5033874511719\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  6,  39, 623,  83,  13], device='cuda:0')\n",
      "Sample labels: tensor([  6,  39, 623,  83,  13], device='cuda:0')\n",
      "Sample logits max values: 502.3431396484375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 326,  262,  661,  286, 6835], device='cuda:0')\n",
      "Sample labels: tensor([ 326,  262,  661,  286, 6835], device='cuda:0')\n",
      "Sample logits max values: 495.8543395996094\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 4156, 25070,   329,   262,  4437], device='cuda:0')\n",
      "Sample labels: tensor([ 4156, 25070,   329,   262,  4437], device='cuda:0')\n",
      "Sample logits max values: 506.4456481933594\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 651,  257, 7026, 7991,  319], device='cuda:0')\n",
      "Sample labels: tensor([ 651,  257, 7026, 7991,  319], device='cuda:0')\n",
      "Sample logits max values: 518.2796630859375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 4445, 34260,    11,   447,   251], device='cuda:0')\n",
      "Sample labels: tensor([ 4445, 34260,    11,   447,   251], device='cuda:0')\n",
      "Sample logits max values: 488.8658752441406\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 287,  534, 6297,   14,  293], device='cuda:0')\n",
      "Sample labels: tensor([ 287,  534, 6297,   14,  293], device='cuda:0')\n",
      "Sample logits max values: 512.8338012695312\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([8680,  284,  683,   13,  198], device='cuda:0')\n",
      "Sample labels: tensor([8680,  284,  683,   13,  198], device='cuda:0')\n",
      "Sample logits max values: 513.3799438476562\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  845,  1593, 17770,   326,   318], device='cuda:0')\n",
      "Sample labels: tensor([  845,  1593, 17770,   326,   318], device='cuda:0')\n",
      "Sample logits max values: 505.22650146484375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([14733,    13,  2893, 24572,   743], device='cuda:0')\n",
      "Sample labels: tensor([14733,    13,  2893, 24572,   743], device='cuda:0')\n",
      "Sample logits max values: 519.5467529296875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  13, 1406,  645,   11,  612], device='cuda:0')\n",
      "Sample labels: tensor([  13, 1406,  645,   11,  612], device='cuda:0')\n",
      "Sample logits max values: 534.0541381835938\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  12, 9446,   13,  383, 1266], device='cuda:0')\n",
      "Sample labels: tensor([  12, 9446,   13,  383, 1266], device='cuda:0')\n",
      "Sample logits max values: 492.8692626953125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  402,   724,  5451,    11, 16640], device='cuda:0')\n",
      "Sample labels: tensor([  402,   724,  5451,    11, 16640], device='cuda:0')\n",
      "Sample logits max values: 511.3494567871094\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 484, 6149,  517, 3835,   13], device='cuda:0')\n",
      "Sample labels: tensor([ 484, 6149,  517, 3835,   13], device='cuda:0')\n",
      "Sample logits max values: 505.0577697753906\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  27,   51,   11, 1439,  420], device='cuda:0')\n",
      "Sample labels: tensor([  27,   51,   11, 1439,  420], device='cuda:0')\n",
      "Sample logits max values: 516.4849853515625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([8339, 2174,  357, 8601, 1654], device='cuda:0')\n",
      "Sample labels: tensor([8339, 2174,  357, 8601, 1654], device='cuda:0')\n",
      "Sample logits max values: 516.5667114257812\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 287, 3576,   13, 5845, 4497], device='cuda:0')\n",
      "Sample labels: tensor([ 287, 3576,   13, 5845, 4497], device='cuda:0')\n",
      "Sample logits max values: 502.7547302246094\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([6427, 4104, 7415,   13, 2735], device='cuda:0')\n",
      "Sample labels: tensor([6427, 4104, 7415,   13, 2735], device='cuda:0')\n",
      "Sample logits max values: 495.1863708496094\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([12796,   326,   645,  1007,  2415], device='cuda:0')\n",
      "Sample labels: tensor([12796,   326,   645,  1007,  2415], device='cuda:0')\n",
      "Sample logits max values: 502.9726867675781\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([5451,   11,  287,  262,  968], device='cuda:0')\n",
      "Sample labels: tensor([5451,   11,  287,  262,  968], device='cuda:0')\n",
      "Sample logits max values: 453.6145935058594\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([26747,  2952,  2823,  1301,   351], device='cuda:0')\n",
      "Sample labels: tensor([26747,  2952,  2823,  1301,   351], device='cuda:0')\n",
      "Sample logits max values: 536.5231323242188\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 4171, 38660, 22078,   625,   465], device='cuda:0')\n",
      "Sample labels: tensor([ 4171, 38660, 22078,   625,   465], device='cuda:0')\n",
      "Sample logits max values: 495.8381042480469\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([5073, 5941,  765,  284, 1624], device='cuda:0')\n",
      "Sample labels: tensor([5073, 5941,  765,  284, 1624], device='cuda:0')\n",
      "Sample logits max values: 494.88311767578125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([22295,  6666,  5938,   198,   198], device='cuda:0')\n",
      "Sample labels: tensor([22295,  6666,  5938,   198,   198], device='cuda:0')\n",
      "Sample logits max values: 538.1375122070312\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([3802,  287,  355,  881, 2420], device='cuda:0')\n",
      "Sample labels: tensor([3802,  287,  355,  881, 2420], device='cuda:0')\n",
      "Sample logits max values: 540.56982421875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  25,  428,  373,  262, 3210], device='cuda:0')\n",
      "Sample labels: tensor([  25,  428,  373,  262, 3210], device='cuda:0')\n",
      "Sample logits max values: 471.5754699707031\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 3712, 30320, 35613, 35507,    12], device='cuda:0')\n",
      "Sample labels: tensor([ 3712, 30320, 35613, 35507,    12], device='cuda:0')\n",
      "Sample logits max values: 481.5932922363281\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  82,  655,  262,  976, 1468], device='cuda:0')\n",
      "Sample labels: tensor([  82,  655,  262,  976, 1468], device='cuda:0')\n",
      "Sample logits max values: 474.0740661621094\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 2489,   329,  2237,   286, 14476], device='cuda:0')\n",
      "Sample labels: tensor([ 2489,   329,  2237,   286, 14476], device='cuda:0')\n",
      "Sample logits max values: 509.437255859375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 262,  886,  286, 2211,   11], device='cuda:0')\n",
      "Sample labels: tensor([ 262,  886,  286, 2211,   11], device='cuda:0')\n",
      "Sample logits max values: 519.3414306640625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  11, 7130, 7038, 1222, 9747], device='cuda:0')\n",
      "Sample labels: tensor([  11, 7130, 7038, 1222, 9747], device='cuda:0')\n",
      "Sample logits max values: 524.849853515625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  357,    34,  2885,     3, 48096], device='cuda:0')\n",
      "Sample labels: tensor([  357,    34,  2885,     3, 48096], device='cuda:0')\n",
      "Sample logits max values: 494.7557373046875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([1630,  393, 1176,  319,  584], device='cuda:0')\n",
      "Sample labels: tensor([1630,  393, 1176,  319,  584], device='cuda:0')\n",
      "Sample logits max values: 491.9373779296875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 1544, 32198,    13,   317, 16605], device='cuda:0')\n",
      "Sample labels: tensor([ 1544, 32198,    13,   317, 16605], device='cuda:0')\n",
      "Sample logits max values: 504.771484375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([10397, 14089, 20171,    11,   290], device='cuda:0')\n",
      "Sample labels: tensor([10397, 14089, 20171,    11,   290], device='cuda:0')\n",
      "Sample logits max values: 540.6672973632812\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([25727,   198,   198, 12041,    25], device='cuda:0')\n",
      "Sample labels: tensor([25727,   198,   198, 12041,    25], device='cuda:0')\n",
      "Sample logits max values: 535.7974243164062\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 257, 1218, 1627, 1863,  351], device='cuda:0')\n",
      "Sample labels: tensor([ 257, 1218, 1627, 1863,  351], device='cuda:0')\n",
      "Sample logits max values: 508.3381652832031\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([4336,  319, 3009,   11, 9524], device='cuda:0')\n",
      "Sample labels: tensor([4336,  319, 3009,   11, 9524], device='cuda:0')\n",
      "Sample logits max values: 510.6083984375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([3017,  867, 4736,  287, 3442], device='cuda:0')\n",
      "Sample labels: tensor([3017,  867, 4736,  287, 3442], device='cuda:0')\n",
      "Sample logits max values: 479.59356689453125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  11, 4216, 7234,  531, 2263], device='cuda:0')\n",
      "Sample labels: tensor([  11, 4216, 7234,  531, 2263], device='cuda:0')\n",
      "Sample logits max values: 522.7722778320312\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([   11,   262, 12841,  3640,   326], device='cuda:0')\n",
      "Sample labels: tensor([   11,   262, 12841,  3640,   326], device='cuda:0')\n",
      "Sample logits max values: 509.72296142578125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([5779,   11,  804,   11,  314], device='cuda:0')\n",
      "Sample labels: tensor([5779,   11,  804,   11,  314], device='cuda:0')\n",
      "Sample logits max values: 493.52301025390625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([25858,   290, 12069,   287,   597], device='cuda:0')\n",
      "Sample labels: tensor([25858,   290, 12069,   287,   597], device='cuda:0')\n",
      "Sample logits max values: 470.6427001953125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([3256,  290, 9392,  607,  284], device='cuda:0')\n",
      "Sample labels: tensor([3256,  290, 9392,  607,  284], device='cuda:0')\n",
      "Sample logits max values: 500.0027160644531\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([14388,   373,  7006,   860,   286], device='cuda:0')\n",
      "Sample labels: tensor([14388,   373,  7006,   860,   286], device='cuda:0')\n",
      "Sample logits max values: 483.08306884765625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([3794,  357, 4093,   40,    8], device='cuda:0')\n",
      "Sample labels: tensor([3794,  357, 4093,   40,    8], device='cuda:0')\n",
      "Sample logits max values: 519.9097290039062\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([24236,   534, 13734,   290,   651], device='cuda:0')\n",
      "Sample labels: tensor([24236,   534, 13734,   290,   651], device='cuda:0')\n",
      "Sample logits max values: 499.75927734375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([9313,  828, 2716,  706,  465], device='cuda:0')\n",
      "Sample labels: tensor([9313,  828, 2716,  706,  465], device='cuda:0')\n",
      "Sample logits max values: 517.9086303710938\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([   11, 36995,   663,  9605,  4788], device='cuda:0')\n",
      "Sample labels: tensor([   11, 36995,   663,  9605,  4788], device='cuda:0')\n",
      "Sample logits max values: 521.8836059570312\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([   12,  1904, 14123,   287,   262], device='cuda:0')\n",
      "Sample labels: tensor([   12,  1904, 14123,   287,   262], device='cuda:0')\n",
      "Sample logits max values: 489.3533630371094\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  198, 14134,   606,  7649,   945], device='cuda:0')\n",
      "Sample labels: tensor([  198, 14134,   606,  7649,   945], device='cuda:0')\n",
      "Sample logits max values: 496.03497314453125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 561,  651,  257, 4633, 3555], device='cuda:0')\n",
      "Sample labels: tensor([ 561,  651,  257, 4633, 3555], device='cuda:0')\n",
      "Sample logits max values: 499.3581848144531\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([13634,    12, 21186,   319,   644], device='cuda:0')\n",
      "Sample labels: tensor([13634,    12, 21186,   319,   644], device='cuda:0')\n",
      "Sample logits max values: 492.7508544921875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 284, 1560,  345,  810,  262], device='cuda:0')\n",
      "Sample labels: tensor([ 284, 1560,  345,  810,  262], device='cuda:0')\n",
      "Sample logits max values: 468.2930908203125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 635, 2585,  326,  257, 1048], device='cuda:0')\n",
      "Sample labels: tensor([ 635, 2585,  326,  257, 1048], device='cuda:0')\n",
      "Sample logits max values: 494.1593017578125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([   13,   679,  7728, 37068, 18198], device='cuda:0')\n",
      "Sample labels: tensor([   13,   679,  7728, 37068, 18198], device='cuda:0')\n",
      "Sample logits max values: 540.81884765625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([2361, 2953,  262, 3726,   30], device='cuda:0')\n",
      "Sample labels: tensor([2361, 2953,  262, 3726,   30], device='cuda:0')\n",
      "Sample logits max values: 463.1773986816406\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  262,  8685, 35855,   287,   607], device='cuda:0')\n",
      "Sample labels: tensor([  262,  8685, 35855,   287,   607], device='cuda:0')\n",
      "Sample logits max values: 521.9288330078125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 2696,    25,   383, 33375,    13], device='cuda:0')\n",
      "Sample labels: tensor([ 2696,    25,   383, 33375,    13], device='cuda:0')\n",
      "Sample logits max values: 492.9382019042969\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([2678,   13, 1318,  318,  517], device='cuda:0')\n",
      "Sample labels: tensor([2678,   13, 1318,  318,  517], device='cuda:0')\n",
      "Sample logits max values: 490.058349609375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  198,   198, 20570,  2067,   198], device='cuda:0')\n",
      "Sample labels: tensor([  198,   198, 20570,  2067,   198], device='cuda:0')\n",
      "Sample logits max values: 508.287353515625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([32341,   290,   262,  6574, 16932], device='cuda:0')\n",
      "Sample labels: tensor([32341,   290,   262,  6574, 16932], device='cuda:0')\n",
      "Sample logits max values: 521.43798828125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  11,  356, 7723,  257, 1178], device='cuda:0')\n",
      "Sample labels: tensor([  11,  356, 7723,  257, 1178], device='cuda:0')\n",
      "Sample logits max values: 509.6938781738281\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([   13,  1119,   389,  6872, 13767], device='cuda:0')\n",
      "Sample labels: tensor([   13,  1119,   389,  6872, 13767], device='cuda:0')\n",
      "Sample logits max values: 535.92138671875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([18062, 24365, 14620,  9363,    11], device='cuda:0')\n",
      "Sample labels: tensor([18062, 24365, 14620,  9363,    11], device='cuda:0')\n",
      "Sample logits max values: 529.9819946289062\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  198,   198, 10798,   286,   262], device='cuda:0')\n",
      "Sample labels: tensor([  198,   198, 10798,   286,   262], device='cuda:0')\n",
      "Sample logits max values: 492.6445617675781\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  584, 13440,   910,   262, 31622], device='cuda:0')\n",
      "Sample labels: tensor([  584, 13440,   910,   262, 31622], device='cuda:0')\n",
      "Sample logits max values: 501.5323181152344\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 3612,  2354,   262, 13360,   286], device='cuda:0')\n",
      "Sample labels: tensor([ 3612,  2354,   262, 13360,   286], device='cuda:0')\n",
      "Sample logits max values: 503.0040588378906\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([20406,   780,   314,   447,   246], device='cuda:0')\n",
      "Sample labels: tensor([20406,   780,   314,   447,   246], device='cuda:0')\n",
      "Sample logits max values: 471.36236572265625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([9674, 2607,  304,   12, 4529], device='cuda:0')\n",
      "Sample labels: tensor([9674, 2607,  304,   12, 4529], device='cuda:0')\n",
      "Sample logits max values: 499.37432861328125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 1910,   284,  8469,    13, 17486], device='cuda:0')\n",
      "Sample labels: tensor([ 1910,   284,  8469,    13, 17486], device='cuda:0')\n",
      "Sample logits max values: 511.3572692871094\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 617, 6597,  326, 5238,  257], device='cuda:0')\n",
      "Sample labels: tensor([ 617, 6597,  326, 5238,  257], device='cuda:0')\n",
      "Sample logits max values: 500.3204345703125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 787,  257, 3580,   13, 4149], device='cuda:0')\n",
      "Sample labels: tensor([ 787,  257, 3580,   13, 4149], device='cuda:0')\n",
      "Sample logits max values: 535.135009765625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([9074,   13,  440,  447,  247], device='cuda:0')\n",
      "Sample labels: tensor([9074,   13,  440,  447,  247], device='cuda:0')\n",
      "Sample logits max values: 510.41064453125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 303, 4488,  329,   11,  447], device='cuda:0')\n",
      "Sample labels: tensor([ 303, 4488,  329,   11,  447], device='cuda:0')\n",
      "Sample logits max values: 465.8659362792969\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([11918,     1,   329,   262, 18183], device='cuda:0')\n",
      "Sample labels: tensor([11918,     1,   329,   262, 18183], device='cuda:0')\n",
      "Sample logits max values: 516.864013671875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 787,  606, 9857,  284, 4297], device='cuda:0')\n",
      "Sample labels: tensor([ 787,  606, 9857,  284, 4297], device='cuda:0')\n",
      "Sample logits max values: 535.3944091796875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  284, 23710,   257,  1994,   662], device='cuda:0')\n",
      "Sample labels: tensor([  284, 23710,   257,  1994,   662], device='cuda:0')\n",
      "Sample logits max values: 469.03240966796875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([1074, 3414,  262, 9412,  286], device='cuda:0')\n",
      "Sample labels: tensor([1074, 3414,  262, 9412,  286], device='cuda:0')\n",
      "Sample logits max values: 500.53076171875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  262, 21594,  9285,   319,   262], device='cuda:0')\n",
      "Sample labels: tensor([  262, 21594,  9285,   319,   262], device='cuda:0')\n",
      "Sample logits max values: 528.8894653320312\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 1336, 12724,  1201,   262,  2739], device='cuda:0')\n",
      "Sample labels: tensor([ 1336, 12724,  1201,   262,  2739], device='cuda:0')\n",
      "Sample logits max values: 485.4582214355469\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 287,  734, 2250,   13, 2773], device='cuda:0')\n",
      "Sample labels: tensor([ 287,  734, 2250,   13, 2773], device='cuda:0')\n",
      "Sample logits max values: 521.2903442382812\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  379, 17304,   262, 10922,  2346], device='cuda:0')\n",
      "Sample labels: tensor([  379, 17304,   262, 10922,  2346], device='cuda:0')\n",
      "Sample logits max values: 549.62255859375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  55, 3933,   13, 4309, 2173], device='cuda:0')\n",
      "Sample labels: tensor([  55, 3933,   13, 4309, 2173], device='cuda:0')\n",
      "Sample logits max values: 524.9617919921875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 352,   11,  830, 1605, 5795], device='cuda:0')\n",
      "Sample labels: tensor([ 352,   11,  830, 1605, 5795], device='cuda:0')\n",
      "Sample logits max values: 505.473876953125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 286, 3759, 1301,   60,  198], device='cuda:0')\n",
      "Sample labels: tensor([ 286, 3759, 1301,   60,  198], device='cuda:0')\n",
      "Sample logits max values: 498.3286437988281\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([5825, 5116, 6797,  588,  257], device='cuda:0')\n",
      "Sample labels: tensor([5825, 5116, 6797,  588,  257], device='cuda:0')\n",
      "Sample logits max values: 502.8727111816406\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 262, 8751,  292, 6386, 9116], device='cuda:0')\n",
      "Sample labels: tensor([ 262, 8751,  292, 6386, 9116], device='cuda:0')\n",
      "Sample logits max values: 520.3257446289062\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 355,  257, 8305, 6260,  475], device='cuda:0')\n",
      "Sample labels: tensor([ 355,  257, 8305, 6260,  475], device='cuda:0')\n",
      "Sample logits max values: 517.12890625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([15633, 12911,   447,   247,   287], device='cuda:0')\n",
      "Sample labels: tensor([15633, 12911,   447,   247,   287], device='cuda:0')\n",
      "Sample logits max values: 469.513916015625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([2612, 5876, 1399,  611,  345], device='cuda:0')\n",
      "Sample labels: tensor([2612, 5876, 1399,  611,  345], device='cuda:0')\n",
      "Sample logits max values: 509.884521484375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 717,  284, 1064,  340,   11], device='cuda:0')\n",
      "Sample labels: tensor([ 717,  284, 1064,  340,   11], device='cuda:0')\n",
      "Sample logits max values: 466.034912109375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([3126, 1528,   13,  198,  198], device='cuda:0')\n",
      "Sample labels: tensor([3126, 1528,   13,  198,  198], device='cuda:0')\n",
      "Sample logits max values: 490.2268981933594\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([1830,  290, 8198, 1938,  481], device='cuda:0')\n",
      "Sample labels: tensor([1830,  290, 8198, 1938,  481], device='cuda:0')\n",
      "Sample logits max values: 500.6524353027344\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([5338, 3636,  470,  765,  284], device='cuda:0')\n",
      "Sample labels: tensor([5338, 3636,  470,  765,  284], device='cuda:0')\n",
      "Sample logits max values: 506.6529846191406\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  318,   257,  2566,   495, 13370], device='cuda:0')\n",
      "Sample labels: tensor([  318,   257,  2566,   495, 13370], device='cuda:0')\n",
      "Sample logits max values: 514.1299438476562\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([1499, 1708,  262, 5070,  447], device='cuda:0')\n",
      "Sample labels: tensor([1499, 1708,  262, 5070,  447], device='cuda:0')\n",
      "Sample logits max values: 518.6015014648438\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([16457,   287,  2274,  4088,    11], device='cuda:0')\n",
      "Sample labels: tensor([16457,   287,  2274,  4088,    11], device='cuda:0')\n",
      "Sample logits max values: 480.59912109375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 554,  262,  886,   11, 2427], device='cuda:0')\n",
      "Sample labels: tensor([ 554,  262,  886,   11, 2427], device='cuda:0')\n",
      "Sample logits max values: 497.14837646484375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([   25, 11083,  6682,   198,   198], device='cuda:0')\n",
      "Sample labels: tensor([   25, 11083,  6682,   198,   198], device='cuda:0')\n",
      "Sample logits max values: 476.2173767089844\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  12,  727, 1200,  290,  257], device='cuda:0')\n",
      "Sample labels: tensor([  12,  727, 1200,  290,  257], device='cuda:0')\n",
      "Sample logits max values: 491.1405944824219\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 766,  257, 3747,   13, 1119], device='cuda:0')\n",
      "Sample labels: tensor([ 766,  257, 3747,   13, 1119], device='cuda:0')\n",
      "Sample logits max values: 486.2286376953125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 379, 2912, 3166,  326, 5741], device='cuda:0')\n",
      "Sample labels: tensor([ 379, 2912, 3166,  326, 5741], device='cuda:0')\n",
      "Sample logits max values: 530.9490966796875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  11,  503,  286, 3252,  326], device='cuda:0')\n",
      "Sample labels: tensor([  11,  503,  286, 3252,  326], device='cuda:0')\n",
      "Sample logits max values: 532.1773681640625\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 198, 2061,  466,  356,  761], device='cuda:0')\n",
      "Sample labels: tensor([ 198, 2061,  466,  356,  761], device='cuda:0')\n",
      "Sample logits max values: 510.303955078125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  526,   198,   198,   464, 41863], device='cuda:0')\n",
      "Sample labels: tensor([  526,   198,   198,   464, 41863], device='cuda:0')\n",
      "Sample logits max values: 486.38897705078125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  407,   804,   922,   329, 12584], device='cuda:0')\n",
      "Sample labels: tensor([  407,   804,   922,   329, 12584], device='cuda:0')\n",
      "Sample logits max values: 499.2934265136719\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 484,  466,  625,  511, 9511], device='cuda:0')\n",
      "Sample labels: tensor([ 484,  466,  625,  511, 9511], device='cuda:0')\n",
      "Sample logits max values: 504.5832824707031\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  262,   749,  3748,   290, 16403], device='cuda:0')\n",
      "Sample labels: tensor([  262,   749,  3748,   290, 16403], device='cuda:0')\n",
      "Sample logits max values: 512.0653076171875\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([17499,    13,   198,   198,   464], device='cuda:0')\n",
      "Sample labels: tensor([17499,    13,   198,   198,   464], device='cuda:0')\n",
      "Sample logits max values: 462.5120849609375\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([  484,   262,  1938,   561, 11148], device='cuda:0')\n",
      "Sample labels: tensor([  484,   262,  1938,   561, 11148], device='cuda:0')\n",
      "Sample logits max values: 496.7540283203125\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([ 286,  262, 3356, 1626,  262], device='cuda:0')\n",
      "Sample labels: tensor([ 286,  262, 3356, 1626,  262], device='cuda:0')\n",
      "Sample logits max values: 491.0688781738281\n",
      "loss: 0.0\n",
      "Input IDs shape: torch.Size([4, 1024])\n",
      "Labels shape: torch.Size([4, 1024])\n",
      "Logits shape: torch.Size([4, 1024, 50257])\n",
      "Sample input_ids: tensor([   81,  1045, 46668,  1734,  8591], device='cuda:0')\n",
      "Sample labels: tensor([   81,  1045, 46668,  1734,  8591], device='cuda:0')\n",
      "Sample logits max values: 466.2401123046875\n",
      "loss: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/transformers/trainer.py:2560\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2553\u001b[39m context = (\n\u001b[32m   2554\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2556\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2557\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2558\u001b[39m )\n\u001b[32m   2559\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2560\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2563\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2564\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2565\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2566\u001b[39m ):\n\u001b[32m   2567\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2568\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/transformers/trainer.py:3736\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3733\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3735\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3736\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3738\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3739\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3740\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3741\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3742\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/transformers/trainer.py:3801\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3799\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3800\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3801\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3802\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3803\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/transformer-examples/models/roformer.py:73\u001b[39m, in \u001b[36mRoFormerForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, labels)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask=\u001b[38;5;28;01mNone\u001b[39;00m, labels=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     hidden = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     logits = \u001b[38;5;28mself\u001b[39m.lm_head(hidden) \u001b[38;5;66;03m# [batch_size, sequence_length, vocab_size]\u001b[39;00m\n\u001b[32m     75\u001b[39m     loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/transformer-examples/models/roformer.py:61\u001b[39m, in \u001b[36mRoFormerEncoder.forward\u001b[39m\u001b[34m(self, input_ids, mask)\u001b[39m\n\u001b[32m     58\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/transformer-examples/models/roformer.py:36\u001b[39m, in \u001b[36mRoFormerEncoderLayer.forward\u001b[39m\u001b[34m(self, x, mask)\u001b[39m\n\u001b[32m     33\u001b[39m batch_size, seq_len = x.shape[\u001b[32m0\u001b[39m], x.shape[\u001b[32m1\u001b[39m]\n\u001b[32m     34\u001b[39m x_reshaped = x.view(batch_size, seq_len, \u001b[38;5;28mself\u001b[39m.config.num_heads, \u001b[38;5;28mself\u001b[39m.config.per_head_dim).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m attn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous().view(batch_size, seq_len, \u001b[38;5;28mself\u001b[39m.config.d_model)\n\u001b[32m     39\u001b[39m x = x + \u001b[38;5;28mself\u001b[39m.dropout1(attn_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/venvs/transformer-examples/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/transformer-examples/attention/multi_head_attention.py:47\u001b[39m, in \u001b[36mMultiHeadAttention.forward\u001b[39m\u001b[34m(self, q, k, v, mask)\u001b[39m\n\u001b[32m     45\u001b[39m causal_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=\u001b[32m1\u001b[39m).bool()\n\u001b[32m     46\u001b[39m causal_mask = causal_mask.unsqueeze(\u001b[32m0\u001b[39m).unsqueeze(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# [1, 1, seq_len, seq_len]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m causal_mask = \u001b[43mcausal_mask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m all_K = []\n\u001b[32m     50\u001b[39m all_Q = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating the model but before training\n",
    "print(\"Checking model initialization:\")\n",
    "print(f\"Embedding weight mean: {model.backbone.embeddings.weight.mean().item():.6f}\")\n",
    "print(f\"Embedding weight std: {model.backbone.embeddings.weight.std().item():.6f}\")\n",
    "\n",
    "# Sample a small batch\n",
    "sample_batch = next(iter(trainer.get_train_dataloader()))\n",
    "sample_input_ids = sample_batch['input_ids'].to(device)\n",
    "sample_labels = sample_batch['labels'].to(device)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(sample_input_ids, labels=sample_labels)\n",
    "print(f\"\\nSample batch statistics:\")\n",
    "print(f\"Input shape: {sample_input_ids.shape}\")\n",
    "print(f\"Labels shape: {sample_labels.shape}\")\n",
    "print(f\"Loss: {outputs['loss'].item():.6f}\")\n",
    "print(f\"Logits mean: {outputs['logits'].mean().item():.6f}\")\n",
    "print(f\"Logits std: {outputs['logits'].std().item():.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer Examples",
   "language": "python",
   "name": "transformer-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
