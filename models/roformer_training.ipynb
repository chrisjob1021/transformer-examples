{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugpy is already listening: Can't listen for client connections: [Errno 98] Address already in use\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    import debugpy\n",
    "    \n",
    "    # Try to listen on the port, catch exception if already listening\n",
    "    try:\n",
    "        debugpy.listen((\"localhost\", 5678))\n",
    "        print(\"Debugpy is listening on localhost:5678\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Debugpy is already listening: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from utils import TrainingConfig, Config\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # or your custom one\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "training_config = TrainingConfig()\n",
    "config = Config(vocab_size=tokenizer.vocab_size,\n",
    "d_model=768, num_heads=12, ffn_dim=3072,\n",
    "num_layers=12, max_seq_len=tokenizer.model_max_length )\n",
    "\n",
    "if False:\n",
    "    # Create a config dictionary for the model\n",
    "    config_dict = {k: getattr(config, k) for k in vars(config) \n",
    "                if not k.startswith('_') and not callable(getattr(config, k))}\n",
    "\n",
    "    # Save the config as JSON\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    with open(os.path.join(savepath, \"config.json\"), \"w\") as f:\n",
    "        json.dump(config_dict, f, indent=2)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "savepath = \"/home/chrisobrien/dev/transformer-examples/models/roformer-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c97ab8d62a84926a902e820a086764d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    # 1. Load the raw text\n",
    "    ds = load_dataset(\"openwebtext\", split=\"train\", trust_remote_code=True)\n",
    "\n",
    "    if False:\n",
    "        ds = ds.select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from datasets import load_from_disk\n",
    "\n",
    "    tokenized = load_from_disk(\"gpt2_tokenized_openwebtext\")\n",
    "    tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa047402b24b40259c2744ab462d40d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/8013769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(\n",
    "            batch[\"text\"],\n",
    "            truncation=False,\n",
    "            # max_length=config.max_seq_len,\n",
    "            padding=False,\n",
    "            # return_tensors=\"pt\",\n",
    "        ).to(device)\n",
    "\n",
    "    tokenized = ds.map(tokenize, batched=True, remove_columns=[\"text\"], num_proc=24)\n",
    "    # tokenized = tokenized.remove_columns([\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized[4]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 8013769\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc115ead18e4ebda431d6614ca62cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    def group_texts(batch):\n",
    "        concatenated = sum(batch[\"input_ids\"], [])\n",
    "        total_length = len(concatenated)\n",
    "        total_length = (total_length // config.max_seq_len) * config.max_seq_len\n",
    "        result = {\n",
    "            \"input_ids\": [concatenated[i:i+config.max_seq_len] for i in range(0, total_length, config.max_seq_len)]\n",
    "        }\n",
    "        return result\n",
    "    \n",
    "    lm_dataset = tokenized.remove_columns([\"attention_mask\"])\n",
    "    if False: lm_dataset = lm_dataset.select(range(1000))\n",
    "    lm_dataset = lm_dataset.map(group_texts, batched=True, num_proc=24)\n",
    "    lm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids'],\n",
       "    num_rows: 1087\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Save the tokenized dataset to disk\n",
    "    dataset_name = \"gpt2_tokenized_concatenated_openwebtext\"\n",
    "    lm_dataset.save_to_disk(dataset_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6e02bb8b2b4e218a83c36238040cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    from datasets import load_from_disk\n",
    "\n",
    "    lm_dataset = load_from_disk(\"gpt2_tokenized_concatenated_openwebtext\")\n",
    "    lm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[286,\n",
       " 663,\n",
       " 2594,\n",
       " 290,\n",
       " 32153,\n",
       " 1096,\n",
       " 606,\n",
       " 13,\n",
       " 447,\n",
       " 251,\n",
       " 198,\n",
       " 198,\n",
       " 14295,\n",
       " 13922,\n",
       " 11,\n",
       " 257,\n",
       " 5413,\n",
       " 6523,\n",
       " 11,\n",
       " 1139,\n",
       " 262,\n",
       " 1664,\n",
       " 447,\n",
       " 247,\n",
       " 82,\n",
       " 3352,\n",
       " 389,\n",
       " 32293,\n",
       " 13,\n",
       " 679,\n",
       " 1180,\n",
       " 32820,\n",
       " 1022,\n",
       " 262,\n",
       " 6168,\n",
       " 12729,\n",
       " 11,\n",
       " 635,\n",
       " 1900,\n",
       " 355,\n",
       " 262,\n",
       " 2846,\n",
       " 286,\n",
       " 779,\n",
       " 11,\n",
       " 326,\n",
       " 373,\n",
       " 3421,\n",
       " 319,\n",
       " 3217,\n",
       " 290,\n",
       " 262,\n",
       " 1664,\n",
       " 447,\n",
       " 247,\n",
       " 82,\n",
       " 16777,\n",
       " 7820,\n",
       " 11,\n",
       " 543,\n",
       " 373,\n",
       " 938,\n",
       " 6153,\n",
       " 287,\n",
       " 3035,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 447,\n",
       " 250,\n",
       " 5886,\n",
       " 262,\n",
       " 812,\n",
       " 11,\n",
       " 356,\n",
       " 423,\n",
       " 9835,\n",
       " 7981,\n",
       " 2985,\n",
       " 326,\n",
       " 356,\n",
       " 743,\n",
       " 779,\n",
       " 511,\n",
       " 2695,\n",
       " 284,\n",
       " 2987,\n",
       " 262,\n",
       " 2594,\n",
       " 484,\n",
       " 3328,\n",
       " 11,\n",
       " 447,\n",
       " 251,\n",
       " 1770,\n",
       " 13,\n",
       " 13922,\n",
       " 531,\n",
       " 287,\n",
       " 257,\n",
       " 3194,\n",
       " 2643,\n",
       " 13,\n",
       " 564,\n",
       " 250,\n",
       " 1890,\n",
       " 4554,\n",
       " 11,\n",
       " 356,\n",
       " 16602,\n",
       " 2695,\n",
       " 284,\n",
       " 2987,\n",
       " 674,\n",
       " 18084,\n",
       " 290,\n",
       " 18953,\n",
       " 16628,\n",
       " 287,\n",
       " 1502,\n",
       " 284,\n",
       " 1394,\n",
       " 4297,\n",
       " 3338,\n",
       " 13,\n",
       " 775,\n",
       " 635,\n",
       " 466,\n",
       " 340,\n",
       " 284,\n",
       " 1205,\n",
       " 649,\n",
       " 1720,\n",
       " 3033,\n",
       " 884,\n",
       " 355,\n",
       " 304,\n",
       " 12,\n",
       " 4529,\n",
       " 17851,\n",
       " 1634,\n",
       " 284,\n",
       " 16481,\n",
       " 2092,\n",
       " 3709,\n",
       " 588,\n",
       " 8440,\n",
       " 29946,\n",
       " 287,\n",
       " 257,\n",
       " 2219,\n",
       " 9483,\n",
       " 11,\n",
       " 393,\n",
       " 284,\n",
       " 6338,\n",
       " 751,\n",
       " 11845,\n",
       " 42851,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 447,\n",
       " 250,\n",
       " 4864,\n",
       " 11,\n",
       " 447,\n",
       " 251,\n",
       " 339,\n",
       " 2087,\n",
       " 11,\n",
       " 564,\n",
       " 250,\n",
       " 505,\n",
       " 1517,\n",
       " 356,\n",
       " 836,\n",
       " 447,\n",
       " 247,\n",
       " 83,\n",
       " 466,\n",
       " 318,\n",
       " 779,\n",
       " 262,\n",
       " 2695,\n",
       " 286,\n",
       " 674,\n",
       " 4297,\n",
       " 447,\n",
       " 247,\n",
       " 2839,\n",
       " 8062,\n",
       " 290,\n",
       " 4963,\n",
       " 284,\n",
       " 2251,\n",
       " 7977,\n",
       " 8560,\n",
       " 13,\n",
       " 1002,\n",
       " 326,\n",
       " 1683,\n",
       " 2458,\n",
       " 11,\n",
       " 356,\n",
       " 447,\n",
       " 247,\n",
       " 297,\n",
       " 307,\n",
       " 262,\n",
       " 717,\n",
       " 284,\n",
       " 1309,\n",
       " 674,\n",
       " 4297,\n",
       " 760,\n",
       " 13,\n",
       " 447,\n",
       " 251,\n",
       " 198,\n",
       " 198,\n",
       " 33031,\n",
       " 5865,\n",
       " 3205,\n",
       " 10054,\n",
       " 3555,\n",
       " 262,\n",
       " 1388,\n",
       " 1621,\n",
       " 4222,\n",
       " 11767,\n",
       " 345,\n",
       " 821,\n",
       " 407,\n",
       " 257,\n",
       " 9379,\n",
       " 416,\n",
       " 12264,\n",
       " 262,\n",
       " 3091,\n",
       " 13,\n",
       " 17665,\n",
       " 3053,\n",
       " 2209,\n",
       " 13,\n",
       " 4222,\n",
       " 302,\n",
       " 12,\n",
       " 9255,\n",
       " 13,\n",
       " 921,\n",
       " 1276,\n",
       " 2922,\n",
       " 257,\n",
       " 13129,\n",
       " 284,\n",
       " 12383,\n",
       " 284,\n",
       " 13,\n",
       " 5865,\n",
       " 3205,\n",
       " 921,\n",
       " 481,\n",
       " 3328,\n",
       " 7237,\n",
       " 7268,\n",
       " 1705,\n",
       " 2695,\n",
       " 837,\n",
       " 5992,\n",
       " 290,\n",
       " 20699,\n",
       " 422,\n",
       " 383,\n",
       " 968,\n",
       " 1971,\n",
       " 3782,\n",
       " 13,\n",
       " 921,\n",
       " 743,\n",
       " 2172,\n",
       " 12,\n",
       " 448,\n",
       " 379,\n",
       " 597,\n",
       " 640,\n",
       " 13,\n",
       " 921,\n",
       " 4236,\n",
       " 284,\n",
       " 3328,\n",
       " 12209,\n",
       " 5992,\n",
       " 290,\n",
       " 2041,\n",
       " 4394,\n",
       " 329,\n",
       " 383,\n",
       " 968,\n",
       " 1971,\n",
       " 3782,\n",
       " 338,\n",
       " 3186,\n",
       " 290,\n",
       " 2594,\n",
       " 13,\n",
       " 6952,\n",
       " 345,\n",
       " 329,\n",
       " 18412,\n",
       " 13,\n",
       " 1052,\n",
       " 4049,\n",
       " 468,\n",
       " 5091,\n",
       " 13,\n",
       " 4222,\n",
       " 1949,\n",
       " 757,\n",
       " 1568,\n",
       " 13,\n",
       " 3582,\n",
       " 477,\n",
       " 968,\n",
       " 1971,\n",
       " 3782,\n",
       " 16983,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 15905,\n",
       " 447,\n",
       " 247,\n",
       " 82,\n",
       " 649,\n",
       " 2594,\n",
       " 4381,\n",
       " 10975,\n",
       " 691,\n",
       " 663,\n",
       " 1479,\n",
       " 11,\n",
       " 5313,\n",
       " 12,\n",
       " 3106,\n",
       " 3186,\n",
       " 11,\n",
       " 407,\n",
       " 262,\n",
       " 3788,\n",
       " 4056,\n",
       " 326,\n",
       " 3925,\n",
       " 290,\n",
       " 2706,\n",
       " 2822,\n",
       " 572,\n",
       " 262,\n",
       " 18316,\n",
       " 329,\n",
       " 1363,\n",
       " 393,\n",
       " 1597,\n",
       " 779,\n",
       " 13,\n",
       " 632,\n",
       " 8698,\n",
       " 6964,\n",
       " 4529,\n",
       " 11,\n",
       " 290,\n",
       " 663,\n",
       " 3519,\n",
       " 304,\n",
       " 12,\n",
       " 4529,\n",
       " 2139,\n",
       " 11,\n",
       " 30096,\n",
       " 13,\n",
       " 785,\n",
       " 11,\n",
       " 475,\n",
       " 407,\n",
       " 262,\n",
       " 30096,\n",
       " 304,\n",
       " 12,\n",
       " 4529,\n",
       " 290,\n",
       " 11845,\n",
       " 1430,\n",
       " 326,\n",
       " 318,\n",
       " 17033,\n",
       " 9639,\n",
       " 4291,\n",
       " 3644,\n",
       " 1327,\n",
       " 10182,\n",
       " 290,\n",
       " 6768,\n",
       " 973,\n",
       " 416,\n",
       " 10225,\n",
       " 13,\n",
       " 21631,\n",
       " 11,\n",
       " 663,\n",
       " 2989,\n",
       " 3113,\n",
       " 11,\n",
       " 318,\n",
       " 5017,\n",
       " 11,\n",
       " 475,\n",
       " 4455,\n",
       " 19142,\n",
       " 11,\n",
       " 663,\n",
       " 6444,\n",
       " 11,\n",
       " 318,\n",
       " 407,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 4723,\n",
       " 10054,\n",
       " 3555,\n",
       " 262,\n",
       " 1388,\n",
       " 1621,\n",
       " 198,\n",
       " 198,\n",
       " 15905,\n",
       " 447,\n",
       " 247,\n",
       " 82,\n",
       " 13995,\n",
       " 407,\n",
       " 284,\n",
       " 779,\n",
       " 262,\n",
       " 1366,\n",
       " 422,\n",
       " 663,\n",
       " 5313,\n",
       " 2594,\n",
       " 284,\n",
       " 2496,\n",
       " 8560,\n",
       " 468,\n",
       " 617,\n",
       " 16532,\n",
       " 11,\n",
       " 1813,\n",
       " 262,\n",
       " 1664,\n",
       " 447,\n",
       " 247,\n",
       " 82,\n",
       " 11622,\n",
       " 6782,\n",
       " 15446,\n",
       " 13,\n",
       " 383,\n",
       " 1664,\n",
       " 468,\n",
       " 531,\n",
       " 340,\n",
       " 481,\n",
       " 2291,\n",
       " 257,\n",
       " 564,\n",
       " 250,\n",
       " 4598,\n",
       " 407,\n",
       " 2610,\n",
       " 447,\n",
       " 251,\n",
       " 3895,\n",
       " 287,\n",
       " 663,\n",
       " 649,\n",
       " 4455,\n",
       " 19142,\n",
       " 838,\n",
       " 5313,\n",
       " 6444,\n",
       " 326,\n",
       " 15174,\n",
       " 2691,\n",
       " 8560,\n",
       " 2706,\n",
       " 422,\n",
       " 9904,\n",
       " 262,\n",
       " 23182,\n",
       " 13870,\n",
       " 286,\n",
       " 2985,\n",
       " 523,\n",
       " 484,\n",
       " 460,\n",
       " 2496,\n",
       " 20699,\n",
       " 13,\n",
       " 5413,\n",
       " 468,\n",
       " 925,\n",
       " 564,\n",
       " 250,\n",
       " 4598,\n",
       " 407,\n",
       " 2610,\n",
       " 447,\n",
       " 251,\n",
       " 262,\n",
       " 4277,\n",
       " 4634,\n",
       " 319,\n",
       " 262,\n",
       " 649,\n",
       " 2196,\n",
       " 286,\n",
       " 19142,\n",
       " 11,\n",
       " 257,\n",
       " 1445,\n",
       " 326,\n",
       " 468,\n",
       " 4073,\n",
       " 257,\n",
       " 2046,\n",
       " 12135,\n",
       " 1871,\n",
       " 2691,\n",
       " 8560,\n",
       " 2706,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 15905,\n",
       " 447,\n",
       " 247,\n",
       " 82,\n",
       " 4574,\n",
       " 284,\n",
       " 2148,\n",
       " 1365,\n",
       " 6782,\n",
       " 15018,\n",
       " 329,\n",
       " 7008,\n",
       " 2058,\n",
       " 379,\n",
       " 257,\n",
       " 640,\n",
       " 618,\n",
       " 663,\n",
       " 4040,\n",
       " 287,\n",
       " 4455,\n",
       " 8560,\n",
       " 423,\n",
       " 599,\n",
       " 46322,\n",
       " 13,\n",
       " 7467,\n",
       " 8560,\n",
       " 3793,\n",
       " 257,\n",
       " 1402,\n",
       " 13390,\n",
       " 286,\n",
       " 5413,\n",
       " 447,\n",
       " 247,\n",
       " 82,\n",
       " 4045,\n",
       " 1597,\n",
       " 11,\n",
       " 14317,\n",
       " 329,\n",
       " 720,\n",
       " 17,\n",
       " 13,\n",
       " 21,\n",
       " 2997,\n",
       " 11,\n",
       " 393,\n",
       " 546,\n",
       " 513,\n",
       " 13,\n",
       " 20,\n",
       " 1411,\n",
       " 11,\n",
       " 286,\n",
       " 262,\n",
       " 1664,\n",
       " 447,\n",
       " 247,\n",
       " 82,\n",
       " 6426,\n",
       " 1141,\n",
       " 663,\n",
       " 938,\n",
       " 9068,\n",
       " 614,\n",
       " 11,\n",
       " 543,\n",
       " 4444,\n",
       " 2795,\n",
       " 1542,\n",
       " 11,\n",
       " 1864,\n",
       " 284,\n",
       " 5413,\n",
       " 447,\n",
       " 247,\n",
       " 82,\n",
       " 28058,\n",
       " 351,\n",
       " 16145,\n",
       " 17199,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 1537,\n",
       " 340,\n",
       " 318,\n",
       " 2562,\n",
       " 284,\n",
       " 766,\n",
       " 703,\n",
       " 5413,\n",
       " 4297,\n",
       " 1244,\n",
       " 307,\n",
       " 10416,\n",
       " 11,\n",
       " 780,\n",
       " 262,\n",
       " 1180,\n",
       " 17397,\n",
       " 286,\n",
       " 5413,\n",
       " 326,\n",
       " 4538,\n",
       " 290,\n",
       " 19158,\n",
       " 663,\n",
       " 2836,\n",
       " 11704,\n",
       " 290,\n",
       " 6782,\n",
       " 4788,\n",
       " 750,\n",
       " 407,\n",
       " 23794,\n",
       " 326,\n",
       " 262,\n",
       " 2458,\n",
       " 287,\n",
       " 262,\n",
       " 2594,\n",
       " 4381,\n",
       " 561,\n",
       " 5298,\n",
       " 6782,\n",
       " 2683,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 464,\n",
       " 28841,\n",
       " 47131,\n",
       " 286,\n",
       " 262,\n",
       " 2139,\n",
       " 4381,\n",
       " 11,\n",
       " 257,\n",
       " 517,\n",
       " 6276,\n",
       " 7684,\n",
       " 11,\n",
       " 1807,\n",
       " 262,\n",
       " 2458,\n",
       " 547,\n",
       " 523,\n",
       " 1402,\n",
       " 326,\n",
       " 484,\n",
       " 547,\n",
       " 4750,\n",
       " 287,\n",
       " 2932,\n",
       " 287,\n",
       " 257,\n",
       " 22847,\n",
       " 564,\n",
       " 250,\n",
       " 31715,\n",
       " 10483,\n",
       " 26426,\n",
       " 447,\n",
       " 251,\n",
       " 4130,\n",
       " 7256,\n",
       " 284,\n",
       " 5068,\n",
       " 4297,\n",
       " 11,\n",
       " 475,\n",
       " 9775,\n",
       " 12062,\n",
       " 2073,\n",
       " 319,\n",
       " 5413,\n",
       " 447,\n",
       " 247,\n",
       " 82,\n",
       " 5909,\n",
       " 7177,\n",
       " 286,\n",
       " 6355,\n",
       " 5313,\n",
       " 5043,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 15905,\n",
       " 635,\n",
       " 1908,\n",
       " 281,\n",
       " 304,\n",
       " 12,\n",
       " 4529,\n",
       " 546,\n",
       " 262,\n",
       " 1487,\n",
       " 287,\n",
       " 2739,\n",
       " 2932,\n",
       " 284,\n",
       " 477,\n",
       " 286,\n",
       " 663,\n",
       " 29524,\n",
       " 1510,\n",
       " 6964,\n",
       " 4529,\n",
       " 2985,\n",
       " 13,\n",
       " 887,\n",
       " 883,\n",
       " 19748,\n",
       " 2627,\n",
       " 262,\n",
       " 2426,\n",
       " 286,\n",
       " 10927,\n",
       " 2691,\n",
       " 37303,\n",
       " 618,\n",
       " 617,\n",
       " 2985,\n",
       " 4499,\n",
       " 326,\n",
       " 257,\n",
       " 2092,\n",
       " 3275,\n",
       " 11,\n",
       " 1262,\n",
       " 262,\n",
       " 976,\n",
       " 11055,\n",
       " 11,\n",
       " 373,\n",
       " 852,\n",
       " 973,\n",
       " 416,\n",
       " 17110,\n",
       " 284,\n",
       " 14983,\n",
       " 13568,\n",
       " 18953,\n",
       " 13,\n",
       " 7467,\n",
       " 3275,\n",
       " 11490,\n",
       " 7728,\n",
       " 1028,\n",
       " 772,\n",
       " 4756,\n",
       " 262,\n",
       " 6218,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 24441,\n",
       " 5413,\n",
       " 11,\n",
       " 2828,\n",
       " 547,\n",
       " 5670,\n",
       " 407,\n",
       " 319,\n",
       " 1771,\n",
       " 262,\n",
       " 2450,\n",
       " 2458,\n",
       " 5676,\n",
       " 6782,\n",
       " 475,\n",
       " 2138,\n",
       " 319,\n",
       " 257,\n",
       " 1180,\n",
       " 1487,\n",
       " 11,\n",
       " 530,\n",
       " 326,\n",
       " 7095,\n",
       " 262,\n",
       " 2694,\n",
       " 286,\n",
       " 5413,\n",
       " 4297,\n",
       " 284,\n",
       " 20889,\n",
       " 262,\n",
       " 1664,\n",
       " 11,\n",
       " 1390,\n",
       " 287,\n",
       " 257,\n",
       " 1398,\n",
       " 2223,\n",
       " 11,\n",
       " 625,\n",
       " 663,\n",
       " 3186,\n",
       " 13,\n",
       " 383,\n",
       " 649,\n",
       " 4381,\n",
       " 4433,\n",
       " 262,\n",
       " 779,\n",
       " 286,\n",
       " 12765,\n",
       " 26038,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5246,\n",
       " 13,\n",
       " 13922,\n",
       " 531,\n",
       " 262,\n",
       " 1487,\n",
       " 1234,\n",
       " 287,\n",
       " 1295,\n",
       " 319,\n",
       " 3217,\n",
       " 287,\n",
       " 262,\n",
       " 6168,\n",
       " 12729,\n",
       " 564,\n",
       " 250,\n",
       " 20839,\n",
       " 407,\n",
       " 8343,\n",
       " 674,\n",
       " 4683,\n",
       " 6782,\n",
       " 4788,\n",
       " 13,\n",
       " 447,\n",
       " 251,\n",
       " 5845,\n",
       " 4788,\n",
       " 2291,\n",
       " 257,\n",
       " 604,\n",
       " 11,\n",
       " 830,\n",
       " 12,\n",
       " 4775,\n",
       " 1388,\n",
       " 2450,\n",
       " 290,\n",
       " 379,\n",
       " 1551,\n",
       " 1467,\n",
       " 3519,\n",
       " 1720,\n",
       " 12,\n",
       " 11423,\n",
       " 6782,\n",
       " 4788,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 2504,\n",
       " 2346,\n",
       " 318,\n",
       " 281,\n",
       " 1672,\n",
       " 286,\n",
       " 703,\n",
       " 2985,\n",
       " 2314,\n",
       " 5457,\n",
       " 760,\n",
       " 644,\n",
       " 4455,\n",
       " 2706,\n",
       " 389,\n",
       " 1804,\n",
       " 351,\n",
       " 511,\n",
       " 2614,\n",
       " 1321,\n",
       " 11,\n",
       " 531,\n",
       " 5502,\n",
       " 26943,\n",
       " 11,\n",
       " 4640,\n",
       " 3437,\n",
       " 286,\n",
       " 262,\n",
       " 3337,\n",
       " 329,\n",
       " 10231,\n",
       " 20265,\n",
       " 11,\n",
       " 257,\n",
       " 7172,\n",
       " 4800,\n",
       " 1448,\n",
       " 1912,\n",
       " 287,\n",
       " 2669,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 447,\n",
       " 250,\n",
       " 2949,\n",
       " 530,\n",
       " 14759,\n",
       " 703,\n",
       " 477,\n",
       " 428,\n",
       " 1366,\n",
       " 318,\n",
       " 852,\n",
       " 1234,\n",
       " 1978,\n",
       " 290,\n",
       " 852,\n",
       " 973,\n",
       " 11,\n",
       " 447,\n",
       " 251,\n",
       " 339,\n",
       " 531,\n",
       " 13,\n",
       " 564,\n",
       " 250,\n",
       " 3237,\n",
       " 286,\n",
       " 777,\n",
       " 2706,\n",
       " 389,\n",
       " 287,\n",
       " 257,\n",
       " 4875,\n",
       " 5101,\n",
       " 3234,\n",
       " 284,\n",
       " 9839,\n",
       " 1978,\n",
       " 477,\n",
       " 262,\n",
       " 1321,\n",
       " 484,\n",
       " 423,\n",
       " 546,\n",
       " 3925,\n",
       " 13,\n",
       " 1114,\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset[671]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 0:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 1:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 2:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 3:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 4:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 5:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 6:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 7:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 8:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 9:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 10:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 11:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 12:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 13:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 14:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 15:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 16:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 17:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 18:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 19:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 20:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 21:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 22:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 23:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 24:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 25:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 26:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 27:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 28:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 29:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 30:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 31:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 32:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 33:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 34:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 35:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 36:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 37:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 38:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 39:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 40:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 41:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 42:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 43:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 44:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 45:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 46:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 47:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 48:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 49:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 50:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 51:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 52:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 53:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 54:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 55:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 56:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 57:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 58:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 59:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 60:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 61:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 62:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 63:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 64:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 65:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 66:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 67:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 68:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 69:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 70:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 71:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 72:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 73:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 74:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 75:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 76:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 77:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 78:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 79:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 80:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 81:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 82:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 83:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 84:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 85:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 86:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 87:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 88:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 89:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 90:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 91:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 92:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 93:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 94:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 95:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 96:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 97:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 98:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n",
      "\n",
      "Example 99:\n",
      "Sequence length: 1024\n",
      "No padding tokens found\n",
      "No EOS tokens found\n"
     ]
    }
   ],
   "source": [
    "ds = lm_dataset\n",
    "# Let's check a few examples for padding tokens and EOS tokens\n",
    "for i in range(100):  # Check first 5 examples\n",
    "    # Convert to tensor first, then do the comparison\n",
    "    input_ids = torch.tensor(ds[i][\"input_ids\"])\n",
    "    pad_mask = (input_ids == tokenizer.pad_token_id)\n",
    "    pad_count = pad_mask.sum().item()\n",
    "    \n",
    "    # Check for EOS tokens\n",
    "    eos_mask = (input_ids == tokenizer.eos_token_id)\n",
    "    eos_count = eos_mask.sum().item()\n",
    "    \n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Sequence length: {len(input_ids)}\")\n",
    "    \n",
    "    # Check padding tokens\n",
    "    if pad_count > 0:\n",
    "        print(f\"Pad tokens found: {pad_count}\")\n",
    "        # Show where the padding starts\n",
    "        first_pad = (input_ids == tokenizer.pad_token_id).nonzero()[0].item()\n",
    "        print(f\"First padding token at position: {first_pad}\")\n",
    "    else:\n",
    "        print(\"No padding tokens found\")\n",
    "    \n",
    "    # Check EOS tokens\n",
    "    if eos_count > 0:\n",
    "        print(f\"EOS tokens found: {eos_count}\")\n",
    "        # Show where the EOS tokens are\n",
    "        eos_positions = (input_ids == tokenizer.eos_token_id).nonzero().flatten().tolist()\n",
    "        print(f\"EOS token positions: {eos_positions}\")\n",
    "    else:\n",
    "        print(\"No EOS tokens found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 50256, 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized[4]['attention_mask']), tokenized[4]['input_ids'][-1], tokenized[4]['attention_mask'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Load the tokenizer\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # Load the tokenized dataset from disk\n",
    "    from datasets import load_from_disk\n",
    "\n",
    "    dataset_name = \"gpt2_tokenized_openwebtext\"\n",
    "    try:\n",
    "        print(\"Loading tokenized dataset from disk...\")\n",
    "        tokenized = load_from_disk(dataset_name)\n",
    "        print(f\"Successfully loaded tokenized dataset with {len(tokenized)} examples\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Dataset not found at {dataset_name}. Please make sure you've saved the tokenized dataset first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Save the tokenized dataset to disk\n",
    "    dataset_name = \"gpt2_tokenized_openwebtext\"\n",
    "    tokenized.save_to_disk(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Upload to Hugging Face Hub\n",
    "    # You'll need to be logged in to Hugging Face\n",
    "    from huggingface_hub import login\n",
    "\n",
    "    # Login to Hugging Face (you'll need to run this once and enter your token)\n",
    "    # Uncomment the line below when you're ready to login\n",
    "    login(\"hf_xxxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Save the tokenized dataset to disk\n",
    "    dataset_name = \"gpt2_tokenized_openwebtext\"\n",
    "    username = \"chrisjob1021\"\n",
    "\n",
    "    # Upload to Hugging Face Hub\n",
    "    # You'll need to be logged in to Hugging Face\n",
    "    from huggingface_hub import HfApi\n",
    "\n",
    "    # Initialize the Hugging Face API\n",
    "    api = HfApi()\n",
    "\n",
    "    # Upload the dataset to the Hub\n",
    "    # Replace \"your-username/tokenized-openwebtext\" with your desired repository name\n",
    "    try:\n",
    "        api.create_repo(\n",
    "            repo_id=username + \"/\" + dataset_name,\n",
    "            repo_type=\"dataset\",\n",
    "            exist_ok=True\n",
    "        )\n",
    "        \n",
    "        api.upload_folder(\n",
    "            folder_path=dataset_name,\n",
    "            repo_id=username + \"/\" + dataset_name,\n",
    "            repo_type=\"dataset\"\n",
    "        )\n",
    "        \n",
    "        print(\"Dataset successfully uploaded to Hugging Face Hub!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading dataset: {e}\")\n",
    "        print(\"You may need to login first with `login()` or check your permissions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from models import RoFormerForCausalLM, RoFormerEncoder\n",
    "import torch\n",
    "\n",
    "if True:\n",
    "    # model initialization\n",
    "    model_base = RoFormerEncoder(config)\n",
    "    model = RoFormerForCausalLM(model_base, config)\n",
    "if False: model = RoFormerForCausalLM.from_pretrained(savepath)\n",
    "model = model.to(device)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "import os\n",
    "# Get the absolute path for logs\n",
    "log_dir = os.path.join(os.path.dirname(savepath), \"logs\")\n",
    "# Create the logging directory if it doesn't exist\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=savepath,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8, # Accumulate gradients over N steps\n",
    "    #With gradient accumulation (gradient_accumulation_steps=8):\n",
    "        # You split what would have been one batch into 8 smaller micro-batches\n",
    "        # For each micro-batch, you:\n",
    "        # Load 1/8th of the data into memory\n",
    "        # Do a forward pass (storing 1/8th of the activations)\n",
    "        # Do a backward pass (computing 1/8th of the gradients)\n",
    "        # ACCUMULATE the gradients (don't update weights yet)\n",
    "        # Clear the activations (but keep gradients)\n",
    "    \n",
    "    warmup_steps=100,\n",
    "    logging_dir=log_dir,\n",
    "    logging_steps=50,\n",
    "    save_steps=100,\n",
    "    save_total_limit=5,\n",
    "    save_strategy=\"steps\",\n",
    "    save_safetensors=False,\n",
    "    # report_to=\"tensorboard\",\n",
    "    gradient_checkpointing=False,\n",
    "\n",
    "    #With Gradient Checkpointing:\n",
    "        # During the forward pass, only store activations at certain \"checkpoints\"\n",
    "        # During backpropagation, RECOMPUTE the intermediate activations as needed\n",
    "        # This means doing some forward computations twice, but using much less memory\n",
    "    # Without checkpointing, you need to store activations for all 12 layers. With checkpointing, you might only store activations every few layers and recompute the rest during backprop.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=lm_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    trainer.train(resume_from_checkpoint=savepath + \"/checkpoint-210\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = next(iter(trainer.get_train_dataloader()))\n",
    "sample_batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': None,\n",
       " 'logits': tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
       "        grad_fn=<UnsafeViewBackward0>)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample_batch['input_ids'], sample_batch['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Clear CUDA cache to free up GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Print memory stats before and after clearing cache\n",
    "    print(f\"GPU memory allocated before clearing cache: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"GPU memory allocated after clearing cache: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    \n",
    "    # Optional: force garbage collection as well\n",
    "    import gc\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # # After creating the model but before training\n",
    "    # print(f\"Embedding weight mean: {model.backbone.embeddings.weight.mean().item():.6f}\")\n",
    "    # print(f\"Embedding weight std: {model.backbone.embeddings.weight.std().item():.6f}\")\n",
    "\n",
    "    # Sample a small batch\n",
    "    sample_batch = next(iter(trainer.get_train_dataloader()))\n",
    "    sample_input_ids = sample_batch['input_ids'].to(device)\n",
    "    sample_labels = sample_batch['labels'].to(device)\n",
    "    \n",
    "    # Print input_ids\n",
    "    # print(f\"Input IDs sample: {sample_input_ids[0, :10]}\")  # Print first 10 input IDs of first batch\n",
    "    print(f\"Decoded input: {tokenizer.decode(sample_input_ids[0, :10])}\")  # Decode the first 10 tokens\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(sample_input_ids, labels=sample_labels)\n",
    "    # print(f\"\\nSample batch statistics:\")\n",
    "    # print(f\"Input shape: {sample_input_ids.shape}\")\n",
    "    # print(f\"Labels shape: {sample_labels.shape}\")\n",
    "    # print(f\"Labels sample: {sample_labels[0, :10]}\")  # Print first 10 labels of first batch\n",
    "    # print(f\"Decoded labels: {tokenizer.decode([l.item() for l in sample_labels[0, :10] if l.item() != -100])}\")  # Decode the first 10 labels, skipping masked tokens\n",
    "\n",
    "    print(f\"Loss: {outputs['loss'].item():.6f}\")\n",
    "\n",
    "    # print(f\"\\nLogits shape: {outputs['logits'].shape}\")\n",
    "    # # Print shapes of intermediate outputs\n",
    "    sequence_length = sample_input_ids.size(1)\n",
    "    # vocab_size = outputs['logits'].shape[-1]\n",
    "    # print(f\"Flattened logits shape: {outputs['logits'].view(batch_size * sequence_length, vocab_size).shape}\")\n",
    "    # print(f\"Flattened labels shape: {sample_labels.view(batch_size * sequence_length).shape}\")\n",
    "\n",
    "    # print(f\"Logits mean: {outputs['logits'].mean().item():.6f}\")\n",
    "    # print(f\"Logits std: {outputs['logits'].std().item():.6f}\")\n",
    "    # print(f\"Logits sample: {outputs['logits'][0, 0, :5]}\")  # Print first 5 logits of first token\n",
    "    \n",
    "    # print(f\"\\nTop 3 predicted tokens sample: {topk_indices[0, :10]}\")  # Print first 10 sets of predictions\n",
    "    \n",
    "    # Add top-p (nucleus) sampling\n",
    "    logits = outputs['logits'][0, :10]  # First batch, first 10 positions\n",
    "    top_k = 50\n",
    "    topk_values, topk_indices = torch.topk(logits, k=top_k, dim=-1)\n",
    "    softmax_logits = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    \n",
    "    print(f\"\\nComparison - Top-k and Top-p Predictions vs Labels:\")\n",
    "    for i in range(min(5, sequence_length)):\n",
    "        # Top-k results\n",
    "        top_k_tokens = []\n",
    "        for k in range(5):\n",
    "            token = tokenizer.decode(topk_indices[i, k].item())\n",
    "            top_k_tokens.append(f\"{k+1}.'{token}'\")\n",
    "        top_k_str = \" \".join(top_k_tokens)\n",
    "        \n",
    "        # Top-p (nucleus) sampling\n",
    "        sorted_probs, sorted_indices = torch.sort(softmax_logits[i], descending=True)\n",
    "        cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "        nucleus_indices = sorted_indices[cumulative_probs <= 0.9]\n",
    "        nucleus_size = len(nucleus_indices)\n",
    "        \n",
    "        # Sample from the nucleus\n",
    "        if nucleus_size > 0:\n",
    "            nucleus_probs = sorted_probs[:nucleus_size]\n",
    "            nucleus_probs = nucleus_probs / nucleus_probs.sum()  # Renormalize probabilities\n",
    "            nucleus_sample_idx = torch.multinomial(nucleus_probs, 1).item()\n",
    "            nucleus_token_idx = nucleus_indices[nucleus_sample_idx].item()\n",
    "            nucleus_token = tokenizer.decode(nucleus_token_idx)\n",
    "        else:\n",
    "            nucleus_token = tokenizer.decode(sorted_indices[0].item())\n",
    "        # Get actual label\n",
    "        label_token = tokenizer.decode(sample_labels[0, i+1].item()) if sample_labels[0, i+1].item() != -100 else \"[MASKED]\"\n",
    "        # Print results\n",
    "        print(f\"Position {i}:\")\n",
    "        # print(f\"  Top-k: 1.'{top1_token}' 2.'{top2_token}' 3.'{top3_token}'\")\n",
    "        print(f\"  Top-k: {top_k_str}\")\n",
    "        print(f\"  Top-p: nucleus size={nucleus_size} (p=0.9), sampled='{nucleus_token}'\")\n",
    "        print(f\"  Label: '{label_token}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this to your current debugging cell in roformer_training.ipynb\n",
    "if False:\n",
    "    # Existing initialization checks\n",
    "    print(\"Checking model initialization:\")\n",
    "    print(f\"Embedding weight mean: {model.backbone.embeddings.weight.mean().item():.6f}\")\n",
    "    print(f\"Embedding weight std: {model.backbone.embeddings.weight.std().item():.6f}\")\n",
    "\n",
    "    # Sample a small batch\n",
    "    sample_batch = next(iter(trainer.get_train_dataloader()))\n",
    "    sample_input_ids = sample_batch['input_ids'].to(device)\n",
    "    sample_labels = sample_batch['labels'].to(device)\n",
    "    \n",
    "    # Track intermediate values through the model\n",
    "    with torch.no_grad():\n",
    "        # 1. Check embeddings output\n",
    "        print(\"\\n=== Embeddings Layer ===\")\n",
    "        embedded = model.backbone.embeddings(sample_input_ids)\n",
    "        print(f\"Embeddings output mean: {embedded.mean().item():.6f}\")\n",
    "        print(f\"Embeddings output std: {embedded.std().item():.6f}\")\n",
    "        \n",
    "        # 2. Track through each transformer layer\n",
    "        x = embedded\n",
    "        for i, layer in enumerate(model.backbone.layers):\n",
    "            print(f\"\\n=== Transformer Layer {i} ===\")\n",
    "            \n",
    "            # 2.1 Self-attention\n",
    "            # Store original input for residual\n",
    "            layer_input = x\n",
    "            \n",
    "            # Get attention outputs\n",
    "            attn_output = layer.self_attn(\n",
    "                q=x.view(x.size(0), x.size(1), layer.config.num_heads, layer.config.per_head_dim).transpose(1, 2),\n",
    "                k=x.view(x.size(0), x.size(1), layer.config.num_heads, layer.config.per_head_dim).transpose(1, 2),\n",
    "                v=x.view(x.size(0), x.size(1), layer.config.num_heads, layer.config.per_head_dim).transpose(1, 2)\n",
    "            )\n",
    "            \n",
    "            print(f\"Attention scores stats:\")\n",
    "            print(f\"  Mean: {attn_output.mean().item():.6f}\")\n",
    "            print(f\"  Std: {attn_output.std().item():.6f}\")\n",
    "            \n",
    "            # 2.2 First residual + layer norm\n",
    "            x = layer_input + layer.dropout1(attn_output)\n",
    "            x = layer.ln1(x)\n",
    "            print(f\"After first layer norm:\")\n",
    "            print(f\"  Mean: {x.mean().item():.6f}\")\n",
    "            print(f\"  Std: {x.std().item():.6f}\")\n",
    "            \n",
    "            # 2.3 FFN\n",
    "            ffn_output = layer.ffn(x)\n",
    "            print(f\"FFN output stats:\")\n",
    "            print(f\"  Mean: {ffn_output.mean().item():.6f}\")\n",
    "            print(f\"  Std: {ffn_output.std().item():.6f}\")\n",
    "            \n",
    "            # 2.4 Second residual + layer norm\n",
    "            x = x + layer.dropout2(ffn_output)\n",
    "            x = layer.ln2(x)\n",
    "            print(f\"Layer {i} final output:\")\n",
    "            print(f\"  Mean: {x.mean().item():.6f}\")\n",
    "            print(f\"  Std: {x.std().item():.6f}\")\n",
    "            \n",
    "            # Check if output is close to input\n",
    "            similarity = torch.cosine_similarity(layer_input.view(-1), x.view(-1), dim=0)\n",
    "            print(f\"  Cosine similarity with layer input: {similarity.item():.6f}\")\n",
    "        \n",
    "        # 3. Final LM head\n",
    "        print(\"\\n=== LM Head Layer ===\")\n",
    "        logits = model.lm_head(x)\n",
    "        print(f\"Final logits stats:\")\n",
    "        print(f\"  Mean: {logits.mean().item():.6f}\")\n",
    "        print(f\"  Std: {logits.std().item():.6f}\")\n",
    "        \n",
    "        # 4. Check weight tying\n",
    "        print(\"\\n=== Weight Tying Check ===\")\n",
    "        print(f\"Embeddings weight sum: {model.backbone.embeddings.weight.sum().item():.6f}\")\n",
    "        print(f\"LM head weight sum: {model.lm_head.weight.sum().item():.6f}\")\n",
    "        print(f\"Are weights identical? {torch.allclose(model.backbone.embeddings.weight, model.lm_head.weight)}\")\n",
    "        \n",
    "        # 5. Compare predictions with input\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        print(\"\\n=== Input vs Predictions ===\")\n",
    "        print(\"First 5 tokens:\")\n",
    "        for i in range(5):\n",
    "            input_token = tokenizer.decode(sample_input_ids[0, i].item())\n",
    "            pred_token = tokenizer.decode(predictions[0, i].item())\n",
    "            print(f\"Position {i}:\")\n",
    "            print(f\"  Input: '{input_token}'\")\n",
    "            print(f\"  Predicted: '{pred_token}'\")\n",
    "            print(f\"  Token IDs - Input: {sample_input_ids[0, i].item()}, Predicted: {predictions[0, i].item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer Examples",
   "language": "python",
   "name": "transformer-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
