{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugger already running or port in use\n"
     ]
    }
   ],
   "source": [
    "import debugpy\n",
    "\n",
    "# 5678 is the default port used by VS Code\n",
    "# Wait for the debugger to attach\n",
    "try:\n",
    "    debugpy.listen(5678)\n",
    "    # print(\"Waiting for debugger to attach...\")\n",
    "    # debugpy.wait_for_client()\n",
    "    # print(\"Debugger attached!\")\n",
    "except RuntimeError:\n",
    "    print(\"Debugger already running or port in use\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 4.1081e-01, -1.1821e+00],\n",
       "          [ 8.2126e-01, -1.2658e+00],\n",
       "          [ 6.1992e-01, -1.0626e+00],\n",
       "          [ 5.8814e-01, -9.7427e-01],\n",
       "          [ 5.2426e-01, -7.6765e-01],\n",
       "          [ 3.9528e-01, -5.8510e-01],\n",
       "          [ 3.7490e-01, -5.7771e-01],\n",
       "          [ 4.4901e-01, -5.8613e-01],\n",
       "          [ 4.2301e-01, -6.2242e-01],\n",
       "          [ 4.6158e-01, -6.0321e-01]],\n",
       "\n",
       "         [[ 1.7042e-01, -2.1376e-01],\n",
       "          [-4.0214e-01, -6.4470e-01],\n",
       "          [-4.1342e-02,  3.5682e-03],\n",
       "          [-8.6866e-02,  7.5942e-02],\n",
       "          [-3.2046e-01, -2.7346e-01],\n",
       "          [-5.7624e-02,  1.3088e-01],\n",
       "          [-8.9673e-02,  1.1738e-01],\n",
       "          [-6.6467e-02,  3.0486e-01],\n",
       "          [-1.4246e-01,  6.7741e-02],\n",
       "          [-1.3269e-01,  1.7230e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 6.7200e-01, -1.1438e+00],\n",
       "          [ 4.3824e-01, -2.0446e-01],\n",
       "          [ 2.1919e-01, -5.0651e-01],\n",
       "          [ 3.7051e-01, -6.5346e-01],\n",
       "          [ 2.7483e-01, -6.4742e-01],\n",
       "          [ 2.3579e-01, -5.3488e-01],\n",
       "          [ 2.3122e-01, -4.5757e-01],\n",
       "          [ 2.3372e-01, -4.0104e-01],\n",
       "          [ 2.2847e-01, -3.5956e-01],\n",
       "          [ 1.5754e-01, -1.8266e-01]],\n",
       "\n",
       "         [[-1.6435e-01, -5.2234e-01],\n",
       "          [-2.0532e-01, -6.3665e-02],\n",
       "          [ 4.9781e-01,  2.5843e-01],\n",
       "          [-5.3136e-02, -3.6281e-02],\n",
       "          [ 1.1909e-01,  3.9715e-02],\n",
       "          [ 2.0803e-01,  1.3433e-01],\n",
       "          [ 1.7897e-01,  2.5052e-01],\n",
       "          [ 6.7513e-02,  2.1711e-01],\n",
       "          [-1.4344e-01,  5.4206e-02],\n",
       "          [ 9.2815e-04,  9.9138e-02]]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from attention import MultiHeadAttention\n",
    "from utils import Config\n",
    "import torch.nn as nn\n",
    "\n",
    "config = Config(vocab_size=10000, d_model=4, num_heads=2, per_head_dim=2)\n",
    "W_O = nn.Linear(config.d_model, config.d_model)\n",
    "attn = MultiHeadAttention(config, W_O)\n",
    "x = torch.randn(2, 10, config.d_model)\n",
    "o, attn_scores = attn(x)\n",
    "attn_scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer Examples",
   "language": "python",
   "name": "transformer-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
