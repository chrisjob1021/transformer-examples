{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugger already running or port in use\n"
     ]
    }
   ],
   "source": [
    "import debugpy\n",
    "\n",
    "# 5678 is the default port used by VS Code\n",
    "# Wait for the debugger to attach\n",
    "try:\n",
    "    debugpy.listen(5678)\n",
    "    # print(\"Waiting for debugger to attach...\")\n",
    "    # debugpy.wait_for_client()\n",
    "    # print(\"Debugger attached!\")\n",
    "except RuntimeError:\n",
    "    print(\"Debugger already running or port in use\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4043, -0.4586],\n",
       "          [-0.4513, -0.2778],\n",
       "          [-0.4074, -0.2353],\n",
       "          [-0.7886,  0.3582],\n",
       "          [-0.3890,  0.1306],\n",
       "          [-0.4028,  0.0064],\n",
       "          [-0.2961,  0.0528],\n",
       "          [-0.3209,  0.0275],\n",
       "          [-0.3373, -0.1969],\n",
       "          [-0.2935, -0.2062]],\n",
       "\n",
       "         [[ 0.9074,  0.0234],\n",
       "          [ 0.4873, -0.0912],\n",
       "          [-0.7584, -1.3240],\n",
       "          [ 0.1914, -0.3684],\n",
       "          [ 0.0884, -0.1445],\n",
       "          [ 0.0374, -0.4887],\n",
       "          [-0.1234, -0.7087],\n",
       "          [ 0.3546, -0.2294],\n",
       "          [ 0.3854, -0.1950],\n",
       "          [ 0.2231, -0.3994]]],\n",
       "\n",
       "\n",
       "        [[[-1.5093,  0.4623],\n",
       "          [-0.6128, -0.4079],\n",
       "          [-0.3813, -0.5546],\n",
       "          [-0.2701, -0.4044],\n",
       "          [-0.3477, -0.4345],\n",
       "          [-0.4409, -0.5631],\n",
       "          [-0.3711, -0.3726],\n",
       "          [-0.2189, -0.4251],\n",
       "          [-0.1342, -0.4301],\n",
       "          [-0.2538, -0.3827]],\n",
       "\n",
       "         [[-0.0626,  0.2573],\n",
       "          [ 0.2178,  0.3945],\n",
       "          [ 1.0112,  0.6097],\n",
       "          [ 0.3952, -0.1440],\n",
       "          [ 0.7115, -0.1067],\n",
       "          [ 0.7391,  0.1646],\n",
       "          [ 0.4174, -0.2330],\n",
       "          [ 0.3742, -0.0712],\n",
       "          [ 0.5331,  0.0074],\n",
       "          [ 0.3531, -0.2502]]]], device='cuda:0',\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from attention import MultiHeadAttention\n",
    "from utils import Config\n",
    "import torch.nn as nn\n",
    "\n",
    "config = Config(vocab_size=10000, d_model=4, num_heads=2, per_head_dim=2)\n",
    "W_O = nn.Linear(config.d_model, config.d_model)\n",
    "attn = MultiHeadAttention(config, W_O).to(\"cuda\")\n",
    "x = torch.randn(2, 10, config.d_model).to(\"cuda\")\n",
    "o, attn_scores = attn(x)\n",
    "attn_scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer Examples",
   "language": "python",
   "name": "transformer-examples"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
