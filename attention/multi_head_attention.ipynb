{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import debugpy\n",
    "\n",
    "# 5678 is the default port used by VS Code\n",
    "# Wait for the debugger to attach\n",
    "try:\n",
    "    debugpy.listen(5678)\n",
    "    # print(\"Waiting for debugger to attach...\")\n",
    "    # debugpy.wait_for_client()\n",
    "    # print(\"Debugger attached!\")\n",
    "except RuntimeError:\n",
    "    print(\"Debugger already running or port in use\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.2772e-01,  3.8254e-01],\n",
       "          [ 1.2048e-01,  4.2461e-01],\n",
       "          [-4.4931e-01,  1.4204e-01],\n",
       "          [-2.5700e-01,  1.7152e-01],\n",
       "          [-5.1212e-01,  6.9952e-02],\n",
       "          [-3.8610e-01,  1.3390e-01],\n",
       "          [-2.9628e-01,  1.9199e-01],\n",
       "          [-2.3394e-01,  1.5739e-01],\n",
       "          [-3.1313e-01,  1.0684e-01],\n",
       "          [-8.1266e-02,  2.0651e-01]],\n",
       "\n",
       "         [[ 9.3984e-02, -6.7617e-01],\n",
       "          [ 1.8150e-01, -3.5172e-01],\n",
       "          [ 1.1136e-01, -4.2841e-01],\n",
       "          [ 1.3440e-01, -2.2943e-01],\n",
       "          [ 1.1296e-01, -3.2834e-01],\n",
       "          [ 1.5771e-01, -3.8849e-01],\n",
       "          [ 4.8997e-02, -4.5754e-01],\n",
       "          [ 8.2159e-02, -4.3921e-01],\n",
       "          [ 1.2659e-01, -3.3300e-01],\n",
       "          [ 1.2521e-01, -4.1230e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1920e-01,  4.3235e-01],\n",
       "          [-1.3775e-01,  4.2739e-01],\n",
       "          [-1.0083e-01,  3.8834e-01],\n",
       "          [-3.1184e-02,  3.8769e-01],\n",
       "          [ 1.4739e-01,  4.7358e-01],\n",
       "          [-8.6571e-02,  3.5036e-01],\n",
       "          [ 1.7605e-01,  4.8462e-01],\n",
       "          [-4.9721e-02,  3.4004e-01],\n",
       "          [ 5.9514e-02,  3.8709e-01],\n",
       "          [-1.5685e-01,  3.0549e-01]],\n",
       "\n",
       "         [[-1.0328e-02, -3.9987e-02],\n",
       "          [ 8.7285e-02, -6.4083e-02],\n",
       "          [-1.0029e-01, -1.7958e-01],\n",
       "          [-2.7280e-01, -5.1623e-01],\n",
       "          [-1.5807e-01, -3.4541e-01],\n",
       "          [-8.2636e-02, -2.1933e-01],\n",
       "          [-4.3657e-04, -1.5108e-01],\n",
       "          [ 3.7671e-02, -8.7043e-02],\n",
       "          [-2.8308e-02, -2.3222e-01],\n",
       "          [-3.6896e-02, -1.9722e-01]]]], device='cuda:0',\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from attention import MultiHeadAttention\n",
    "from utils import Config\n",
    "import torch.nn as nn\n",
    "\n",
    "config = Config(vocab_size=10000, d_model=4, num_heads=2, per_head_dim=2)\n",
    "W_O = nn.Linear(config.d_model, config.d_model)\n",
    "attn = MultiHeadAttention(config, W_O).to(\"cuda\")\n",
    "x = torch.randn(2, 10, config.d_model).to(\"cuda\")\n",
    "o, attn_scores = attn(x)\n",
    "attn_scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer Examples",
   "language": "python",
   "name": "transformer-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
